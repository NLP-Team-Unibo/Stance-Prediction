{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from torchinfo import summary\n",
    "from ibm_dataset import IBMDebater\n",
    "import utils\n",
    "from train_text import train_loop\n",
    "from models.text_model import TextModel\n",
    "from models.audio_model import AudioModel\n",
    "from models.multimodal_model import MultimodalModel\n",
    "from transformers import DistilBertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from train_multimodal import train_loop\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/ibm_debater/full'\n",
    "text_transform = torchtext.transforms.ToTensor()\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "data = IBMDebater(data_path, 'train', tokenizer=tokenizer, max_audio_len=5, text_transform=text_transform)\n",
    "train_len = int(len(data)*0.7)\n",
    "data_train, data_val = random_split(data, [train_len, len(data) - train_len])\n",
    "\n",
    "small_data_dim = 0.2\n",
    "rnd_idx = np.random.choice(np.array([i for i in range(1, len(data))]), size=int(len(data)*small_data_dim))\n",
    "small_data = torch.utils.data.Subset(data, rnd_idx)\n",
    "train_len = int(len(small_data)*0.7) \n",
    "small_data_train, small_data_val = random_split(small_data, [train_len, len(small_data) - train_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "loader_train = DataLoader(small_data_train,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    collate_fn=utils.batch_generator_multimodal,\n",
    "                    drop_last=True)\n",
    "loader_val = DataLoader(small_data_val,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    collate_fn=utils.batch_generator_multimodal,\n",
    "                    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "MultimodalModel                                              --\n",
       "├─TextModel: 1-1                                             --\n",
       "│    └─DistilBertModel: 2-1                                  --\n",
       "│    │    └─Embeddings: 3-1                                  (23,835,648)\n",
       "│    │    └─Transformer: 3-2                                 85,054,464\n",
       "│    └─Linear: 2-2                                           590,592\n",
       "│    └─Linear: 2-3                                           769\n",
       "│    └─ReLU: 2-4                                             --\n",
       "├─AudioModel: 1-2                                            --\n",
       "│    └─FeatureExtractor: 2-5                                 --\n",
       "│    │    └─ModuleList: 3-3                                  4,200,448\n",
       "│    └─Linear: 2-6                                           8,000\n",
       "│    └─Linear: 2-7                                           513\n",
       "│    └─ReLU: 2-8                                             --\n",
       "├─Linear: 1-3                                                1,281\n",
       "├─ReLU: 1-4                                                  --\n",
       "=====================================================================================\n",
       "Total params: 113,691,715\n",
       "Trainable params: 15,825,475\n",
       "Non-trainable params: 97,866,240\n",
       "====================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultimodalModel(chunk_size=5, audio_hidden_state_dim=32, device='cuda')\n",
    "model.cuda()\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [02:46<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.7058048191908244 train_accuracy: 0.5135135135135135\tval_loss: 0.6931471824645996 val_accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [02:47<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.6931471824645996 train_accuracy: 0.48986486486486486\tval_loss: 0.6931471824645996 val_accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [02:49<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.6931471824645996 train_accuracy: 0.4864864864864865\tval_loss: 0.6931471824645996 val_accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/74 [00:03<04:22,  3.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/prahtz/GoogleDrive/GitHub/NLP_Project/stance_classification_multimodal.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/prahtz/GoogleDrive/GitHub/NLP_Project/stance_classification_multimodal.ipynb#ch0000004?line=0'>1</a>\u001b[0m train_loop(model, loader_train\u001b[39m=\u001b[39;49mloader_train, loader_val\u001b[39m=\u001b[39;49mloader_val, epochs\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/GoogleDrive/GitHub/NLP_Project/train_multimodal.py:13\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, loader_train, loader_val, epochs, device)\u001b[0m\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=9'>10</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=12'>13</a>\u001b[0m     train(model, optimizer, criterion, loader_train, device)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=13'>14</a>\u001b[0m     validate(model, criterion, loader_val, device)\n",
      "File \u001b[0;32m~/GoogleDrive/GitHub/NLP_Project/train_multimodal.py:27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, data_loader, device)\u001b[0m\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=24'>25</a>\u001b[0m waves \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=25'>26</a>\u001b[0m labels \u001b[39m=\u001b[39m data[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=26'>27</a>\u001b[0m output \u001b[39m=\u001b[39m model(input_dict, waves)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=27'>28</a>\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/train_multimodal.py?line=28'>29</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, labels)\n",
      "File \u001b[0;32m~/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GoogleDrive/GitHub/NLP_Project/models/multimodal_model.py:17\u001b[0m, in \u001b[0;36mMultimodalModel.forward\u001b[0;34m(self, text_input, audio_input)\u001b[0m\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/multimodal_model.py?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, text_input, audio_input):\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/multimodal_model.py?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtext_input)\n\u001b[0;32m---> <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/multimodal_model.py?line=16'>17</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maudio_model(audio_input)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/multimodal_model.py?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, y], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/multimodal_model.py?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/env/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/GoogleDrive/GitHub/NLP_Project/models/audio_model.py:27\u001b[0m, in \u001b[0;36mAudioModel.forward\u001b[0;34m(self, waves)\u001b[0m\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/audio_model.py?line=24'>25</a>\u001b[0m outs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/audio_model.py?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m wave \u001b[39min\u001b[39;00m waves:\n\u001b[0;32m---> <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/audio_model.py?line=26'>27</a>\u001b[0m     wave \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/audio_model.py?line=27'>28</a>\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwav2vec2(wave, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     <a href='file:///home/prahtz/GoogleDrive/GitHub/NLP_Project/models/audio_model.py?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop(model, loader_train=loader_train, loader_val=loader_val, epochs=4, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "163f9789a5a304d7da8b497e35078abf9819c9a8bd180034b67bc521774fa763"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
