{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from torchinfo import summary\n",
    "from ibm_dataset import IBMDebater\n",
    "import utils\n",
    "from train_text import train_loop\n",
    "from models.text_model import TextModel\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = torchtext.transforms.ToTensor()\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "data_path = 'data/ibm_debater/full'\n",
    "\n",
    "data = IBMDebater(data_path, 'train', tokenizer=tokenizer, text_transform=text_transform, load_audio=False)\n",
    "train_len = int(len(data)*0.7)\n",
    "data_train, data_val = random_split(data, [train_len, len(data) - train_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "loader_train = DataLoader(data_train,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    collate_fn=utils.batch_generator_text,\n",
    "                    drop_last=True)\n",
    "loader_val = DataLoader(data_val,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    collate_fn=utils.batch_generator_text,\n",
    "                    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "TextModel                                               --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              (23,440,896)\n",
       "│    │    └─Embedding: 3-2                              (393,216)\n",
       "│    │    └─LayerNorm: 3-3                              (1,536)\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             85,054,464\n",
       "├─Linear: 1-2                                           590,592\n",
       "├─Linear: 1-3                                           769\n",
       "├─ReLU: 1-4                                             --\n",
       "================================================================================\n",
       "Total params: 109,481,473\n",
       "Trainable params: 14,767,105\n",
       "Non-trainable params: 94,714,368\n",
       "================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextModel()\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.6811088868366775 train_accuracy: 0.5376344086021505\tval_loss: 0.6221732035279274 val_accuracy: 0.671875\n",
      "train_loss: 0.3237089231530184 train_accuracy: 0.8729838709677419\tval_loss: 0.1835200794506818 val_accuracy: 0.9359375\n",
      "train_loss: 0.12031921399857408 train_accuracy: 0.959005376344086\tval_loss: 0.14195448660757393 val_accuracy: 0.9609375\n",
      "train_loss: 0.08611857353319083 train_accuracy: 0.9717741935483871\tval_loss: 0.14197878866689279 val_accuracy: 0.9546875\n",
      "train_loss: 0.06781581145340718 train_accuracy: 0.9778225806451613\tval_loss: 0.11057145184604451 val_accuracy: 0.96875\n",
      "train_loss: 0.05014113288232556 train_accuracy: 0.9865591397849462\tval_loss: 0.12479066994856111 val_accuracy: 0.9671875\n",
      "train_loss: 0.03370617529607668 train_accuracy: 0.989247311827957\tval_loss: 0.16990083383279853 val_accuracy: 0.95\n",
      "train_loss: 0.02571467857467391 train_accuracy: 0.9932795698924731\tval_loss: 0.13143969392112922 val_accuracy: 0.965625\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, loader_train, loader_val, 8, 'cuda')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
