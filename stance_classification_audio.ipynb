{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import transformers\n",
    "from torchinfo import summary\n",
    "from ibm_dataset import IBMDebater\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "\n",
    "data_path = 'data/ibm_debater/full'\n",
    "\n",
    "data = IBMDebater(data_path, 'train', audio_processor=bundle, max_audio_len=10, load_text=False)\n",
    "train_len = int(len(data)*0.7)\n",
    "data_train, data_val = random_split(data, [train_len, len(data) - train_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "loader_train = DataLoader(data_train,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    collate_fn=utils.batch_generator_wav2vec,\n",
    "                    drop_last=True)\n",
    "loader_val = DataLoader(data_val,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    collate_fn=utils.batch_generator_wav2vec,\n",
    "                    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "Wav2Vec2Model                                           --\n",
       "├─FeatureExtractor: 1-1                                 --\n",
       "│    └─ModuleList: 2-1                                  --\n",
       "│    │    └─ConvLayerBlock: 3-1                         (6,144)\n",
       "│    │    └─ConvLayerBlock: 3-2                         (786,432)\n",
       "│    │    └─ConvLayerBlock: 3-3                         (786,432)\n",
       "│    │    └─ConvLayerBlock: 3-4                         (786,432)\n",
       "│    │    └─ConvLayerBlock: 3-5                         (786,432)\n",
       "│    │    └─ConvLayerBlock: 3-6                         (524,288)\n",
       "│    │    └─ConvLayerBlock: 3-7                         (524,288)\n",
       "├─Encoder: 1-2                                          --\n",
       "│    └─FeatureProjection: 2-2                           --\n",
       "│    │    └─LayerNorm: 3-8                              (1,024)\n",
       "│    │    └─Linear: 3-9                                 (393,984)\n",
       "│    │    └─Dropout: 3-10                               --\n",
       "│    └─Transformer: 2-3                                 --\n",
       "│    │    └─ConvolutionalPositionalEmbedding: 3-11      (4,719,488)\n",
       "│    │    └─LayerNorm: 3-12                             (1,536)\n",
       "│    │    └─Dropout: 3-13                               --\n",
       "│    │    └─ModuleList: 3-14                            (85,054,464)\n",
       "================================================================================\n",
       "Total params: 94,370,944\n",
       "Trainable params: 0\n",
       "Non-trainable params: 94,370,944\n",
       "================================================================================"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bundle.get_model().cuda()\n",
    "\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "dim = 10\n",
    "linear = nn.Linear(499, dim, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = 'cuda'\n",
    "with torch.inference_mode():\n",
    "    for i, data in enumerate(loader_train):\n",
    "        #wave, labels = [x.to(device) for x in data]\n",
    "        waves, labels = data\n",
    "        outs = []\n",
    "        for wave in waves:\n",
    "            wave = wave.to(device)\n",
    "            x, _ = model.feature_extractor(wave, length=None)\n",
    "            x = x.transpose(1, 2)\n",
    "            x = linear(x)\n",
    "            outs.append(x)\n",
    "            #del wave\n",
    "        print('Batch:', i)\n",
    "        #emission, _ = model.feature_extractor(wave, length=None)\n",
    "        #print(emission.size())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
